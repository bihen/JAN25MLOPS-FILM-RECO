{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QFPy6pvYfhu6",
    "outputId": "e19ff840-86d0-4909-ac39-1ef3bd9713a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings:\n",
      "   userId  movieId  rating   timestamp\n",
      "0       1        2     3.5  1112486027\n",
      "1       1       29     3.5  1112484676\n",
      "2       1       32     3.5  1112484819\n",
      "3       1       47     3.5  1112484727\n",
      "4       1       50     3.5  1112484580\n",
      "\n",
      "Tags:\n",
      "   userId  movieId            tag   timestamp\n",
      "0      18     4141    Mark Waters  1240597180\n",
      "1      65      208      dark hero  1368150078\n",
      "2      65      353      dark hero  1368150079\n",
      "3      65      521  noir thriller  1368149983\n",
      "4      65      592      dark hero  1368150078\n",
      "\n",
      "Movies:\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "\n",
      "Links:\n",
      "   movieId  imdbId   tmdbId\n",
      "0        1  114709    862.0\n",
      "1        2  113497   8844.0\n",
      "2        3  113228  15602.0\n",
      "3        4  114885  31357.0\n",
      "4        5  113041  11862.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "# Load datasets\n",
    "links = pd.read_csv(\"../data/links.csv\")\n",
    "movies = pd.read_csv(\"../data/movies.csv\")\n",
    "ratings = pd.read_csv(\"../data/ratings.csv\") \n",
    "tags = pd.read_csv(\"../data/tags.csv\")\n",
    "# genome_tags = pd.read_csv('/content/drive/MyDrive/ml-20m-mix/genome-tags.csv')\n",
    "# genome_scores = pd.read_csv('/content/drive/MyDrive/ml-20m-mix/genome-scores.csv')\n",
    "\n",
    "# Display the first few rows of each DataFrame to understand the structure\n",
    "print(\"Ratings:\")\n",
    "print(ratings.head())\n",
    "\n",
    "print(\"\\nTags:\")\n",
    "print(tags.head())\n",
    "\n",
    "print(\"\\nMovies:\")\n",
    "print(movies.head())\n",
    "\n",
    "print(\"\\nLinks:\")\n",
    "print(links.head())\n",
    "\n",
    "# print(\"\\nGenome Tags:\")\n",
    "# print(genome_tags.head())\n",
    "\n",
    "# print(\"\\nGenome Scores:\")\n",
    "# print(genome_scores.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "id": "_A_KjUzhf_Q3",
    "outputId": "32dd2d36-fefd-471b-9bcd-310fb7c0eb22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000263 entries, 0 to 20000262\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   userId     int64  \n",
      " 1   movieId    int64  \n",
      " 2   rating     float64\n",
      " 3   timestamp  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 610.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 465564 entries, 0 to 465563\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   userId     465564 non-null  int64 \n",
      " 1   movieId    465564 non-null  int64 \n",
      " 2   tag        465548 non-null  object\n",
      " 3   timestamp  465564 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 14.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27278 entries, 0 to 27277\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  27278 non-null  int64 \n",
      " 1   title    27278 non-null  object\n",
      " 2   genres   27278 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 639.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27278 entries, 0 to 27277\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   movieId  27278 non-null  int64  \n",
      " 1   imdbId   27278 non-null  int64  \n",
      " 2   tmdbId   27026 non-null  float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 639.5 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ratings.info())\n",
    "display(tags.info())\n",
    "display(movies.info())\n",
    "display(links.info())\n",
    "# display(genome_tags.info())\n",
    "# display(genome_scores.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "id": "SgQulx1ikFR0",
    "outputId": "9ea4139d-c6e4-441c-e0c0-bdbd92de98a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000263 entries, 0 to 20000262\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype         \n",
      "---  ------     -----         \n",
      " 0   userId     int64         \n",
      " 1   movieId    int64         \n",
      " 2   rating     float64       \n",
      " 3   timestamp  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), int64(2)\n",
      "memory usage: 610.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 465548 entries, 0 to 465563\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype         \n",
      "---  ------     --------------   -----         \n",
      " 0   userId     465548 non-null  int64         \n",
      " 1   movieId    465548 non-null  int64         \n",
      " 2   tag        465548 non-null  object        \n",
      " 3   timestamp  465548 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(2), object(1)\n",
      "memory usage: 17.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 27026 entries, 0 to 27277\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   movieId  27026 non-null  int64  \n",
      " 1   imdbId   27026 non-null  int64  \n",
      " 2   tmdbId   27026 non-null  float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 844.6 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Handling missing values\n",
    "tags.dropna(subset=['tag'], inplace=True)\n",
    "links.dropna(subset=['tmdbId'], inplace=True)\n",
    "\n",
    "# Converting timestamps to datetime (if needed for analysis)\n",
    "ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "tags['timestamp'] = pd.to_datetime(tags['timestamp'], unit='s')\n",
    "\n",
    "# Removing duplicates if any\n",
    "ratings.drop_duplicates(inplace=True)\n",
    "tags.drop_duplicates(inplace=True)\n",
    "movies.drop_duplicates(inplace=True)\n",
    "links.drop_duplicates(inplace=True)\n",
    "# genome_tags.drop_duplicates(inplace=True)\n",
    "# genome_scores.drop_duplicates(inplace=True)\n",
    "\n",
    "# Display cleaned data info\n",
    "display(ratings.info())\n",
    "display(tags.info())\n",
    "display(links.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tp8aleEskG6m",
    "outputId": "1df424df-4026-4bb6-c3d8-05eca5af6c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been prepared for collaborative filtering.\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader\n",
    "\n",
    "# Define the reader format for Surprise\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# Load the ratings dataset into Surprise's Dataset format\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Splitting the data into training and testing (e.g., 80% training, 20% testing)\n",
    "from surprise.model_selection import train_test_split\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data has been prepared for collaborative filtering.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XX3CGdniof22",
    "outputId": "545e3d91-8dde-445f-a137-a80d7116f3aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7865\n",
      "RMSE of the SVD model: 0.7865\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Instantiate the SVD model\n",
    "svd = SVD()\n",
    "\n",
    "# Train the model on the training set\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = svd.test(testset)\n",
    "\n",
    "# Calculate RMSE to evaluate model performance\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"RMSE of the SVD model: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save Model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/20M_Model_SVD.sav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mdump(svd, \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "filename = \"../models/20M_Model_SVD.sav\"\n",
    "pickle.dump(svd, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7865\n",
      "RMSE of the SVD model: 0.7865\n"
     ]
    }
   ],
   "source": [
    "# Test loading\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "filename = \"../models/20M_Model_SVD.sav\"\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# Make predictions on the test set\n",
    "predictions = loaded_model.test(testset)\n",
    "\n",
    "# Calculate RMSE to evaluate model performance\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"RMSE of the SVD model: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gs7D0bpUpgZ3",
    "outputId": "d4cd4e90-dfa5-4297-aa99-2aa882f0f130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8134\n",
      "RMSE of the SVD++ model: 0.8134\n",
      "RMSE: 0.8551\n",
      "RMSE of the Slope One model: 0.8551\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVDpp, SlopeOne\n",
    "\n",
    "# Instantiate the SVD++ model\n",
    "svdpp = SVDpp()\n",
    "\n",
    "# Train the model on the training set\n",
    "svdpp.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_svdpp = svdpp.test(testset)\n",
    "\n",
    "# Calculate RMSE for SVD++\n",
    "rmse_svdpp = accuracy.rmse(predictions_svdpp)\n",
    "print(f\"RMSE of the SVD++ model: {rmse_svdpp:.4f}\")\n",
    "\n",
    "# Instantiate the Slope One model\n",
    "slope_one = SlopeOne()\n",
    "\n",
    "# Train the model on the training set\n",
    "slope_one.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_slope_one = slope_one.test(testset)\n",
    "\n",
    "# Calculate RMSE for Slope One\n",
    "rmse_slope_one = accuracy.rmse(predictions_slope_one)\n",
    "print(f\"RMSE of the Slope One model: {rmse_slope_one:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "filename = \"../models/20M_Model_SVDPlusPlus.sav\"\n",
    "pickle.dump(svdpp, open(filename, \"wb\"))\n",
    "filename = \"../models/20M_Model_SlopeOne.sav\"\n",
    "pickle.dump(slope_one, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "myzhsXhj0JMw",
    "outputId": "d1a85343-7b3d-435f-95be-c5de0701d430"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birne\\anaconda3\\envs\\SEP24-BDS-INT-FILM-RECO\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score obtained: 0.7956\n",
      "Best parameters: {'n_factors': 50, 'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.02}\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for SVD\n",
    "param_grid = {\n",
    "    'n_factors': [50, 100, 150],\n",
    "    'n_epochs': [20, 50],\n",
    "    'lr_all': [0.005, 0.01],\n",
    "    'reg_all': [0.02, 0.1]\n",
    "}\n",
    "\n",
    "# Perform Grid Search Cross Validation\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "\n",
    "# Fit the grid searchz6t\n",
    "gs.fit(data)\n",
    "\n",
    "# Get the best score and best parameters\n",
    "print(f\"Best RMSE score obtained: {gs.best_score['rmse']:.4f}\")\n",
    "print(f\"Best parameters: {gs.best_params['rmse']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1b49ac7ce50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVDgs = SVD(n_factors=50, n_epochs=20, lr_all=0.005, reg_all=0.02)\n",
    "SVDgs.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "filename = \"../models/20M_Model_SVDGridCV.sav\"\n",
    "pickle.dump(SVDgs, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojta8dzznNEx",
    "outputId": "fa94ec73-684f-45ee-f598-0d55590664a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8342\n",
      "RMSE of the KNNWithMeans model: 0.8342\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8334\n",
      "RMSE of the KNNBaseline model: 0.8334\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNWithMeans, KNNBaseline\n",
    "\n",
    "# Define item-based similarity options\n",
    "sim_options = {\n",
    "    'name': 'cosine',  # Can also try 'pearson'\n",
    "    'user_based': False  # Use item-based collaborative filtering\n",
    "}\n",
    "\n",
    "# Instantiate and train the KNNWithMeans model\n",
    "knn_means = KNNWithMeans(sim_options=sim_options)\n",
    "knn_means.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set for KNNWithMeans\n",
    "predictions_knn_means = knn_means.test(testset)\n",
    "\n",
    "# Calculate RMSE for KNNWithMeans\n",
    "rmse_knn_means = accuracy.rmse(predictions_knn_means)\n",
    "print(f\"RMSE of the KNNWithMeans model: {rmse_knn_means:.4f}\")\n",
    "\n",
    "# Instantiate and train the KNNBaseline model\n",
    "knn_baseline = KNNBaseline(sim_options=sim_options)\n",
    "knn_baseline.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set for KNNBaseline\n",
    "predictions_knn_baseline = knn_baseline.test(testset)\n",
    "\n",
    "# Calculate RMSE for KNNBaseline\n",
    "rmse_knn_baseline = accuracy.rmse(predictions_knn_baseline)\n",
    "print(f\"RMSE of the KNNBaseline model: {rmse_knn_baseline:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "filename = \"../models/20M_Model_KNNWithMeans.sav\"\n",
    "pickle.dump(knn_means, open(filename, \"wb\"))\n",
    "filename = \"../models/20M_Model_KNNBaseline.sav\"\n",
    "pickle.dump(knn_baseline, open(filename, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sq1xFS7jBFGE",
    "outputId": "f08c6b68-fb9f-4f1d-d91b-daba24ee88fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birne\\anaconda3\\envs\\SEP24-BDS-INT-FILM-RECO\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import RandomizedSearchCV\n",
    "from surprise import SVD\n",
    "\n",
    "# Define a refined parameter grid\n",
    "param_grid = {\n",
    "    'n_factors': [100, 125, 150, 175, 200],     # Number of latent factors\n",
    "    'n_epochs': [30, 50, 70],                   # Number of epochs\n",
    "    'lr_all': [0.005, 0.0075, 0.01],            # Learning rate for all parameters\n",
    "    'reg_all': [0.05, 0.1, 0.15]                # Regularization term for all parameters\n",
    "}\n",
    "\n",
    "# Perform Randomized Search Cross Validation\n",
    "rs = RandomizedSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_iter=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the randomized search\n",
    "rs.fit(data)\n",
    "          \n",
    "# Get the best score and best parameters\n",
    "print(f\"Best RMSE score obtained: {rs.best_score['rmse']:.4f}\")\n",
    "print(f\"Best parameters: {rs.best_params['rmse']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hLs7TtH1CN9y",
    "outputId": "3db8ff5b-a452-4cd9-c97a-137bf5500e5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8169\n",
      "RMSE of the tuned SVD model: 0.8169\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary module\n",
    "from surprise import SVD\n",
    "\n",
    "# Instantiate the SVD model with the best parameters from RandomizedSearchCV\n",
    "best_svd = SVD(n_factors=200, n_epochs=70, lr_all=0.0075, reg_all=0.1)\n",
    "\n",
    "# Train the model on the training set\n",
    "best_svd.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_best_svd = best_svd.test(testset)\n",
    "\n",
    "# Calculate RMSE to evaluate the model performance\n",
    "from surprise import accuracy\n",
    "rmse_best_svd = accuracy.rmse(predictions_best_svd)\n",
    "print(f\"RMSE of the tuned SVD model: {rmse_best_svd:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "filename = \"../models/20M_Model_optimizedSVD.sav\"\n",
    "pickle.dump(best_svd, open(filename, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../models/20M_Model_optimizedSVD.sav\"\n",
    "# load the model from disk\n",
    "best_svd = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K71BDB9OC_7_"
   },
   "source": [
    "#Step 2: Building a Hybrid Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTE2IH02DCCU",
    "outputId": "5ed549f0-fded-4075-da4e-c36a05709447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres Similarity Matrix (first 5 movies):\n",
      "[[1.         0.81339357 0.15918745 0.14385421 0.26417526]\n",
      " [0.81339357 1.         0.         0.         0.        ]\n",
      " [0.15918745 0.         1.         0.90367808 0.60258272]\n",
      " [0.14385421 0.         0.90367808 1.         0.5445408 ]\n",
      " [0.26417526 0.         0.60258272 0.5445408  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Extract genres from the movies dataset\n",
    "movies['genres'] = movies['genres'].str.replace('|', ' ')\n",
    "\n",
    "# Use TF-IDF Vectorizer to convert genres into feature vectors\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(movies['genres'])\n",
    "\n",
    "# Compute cosine similarity between movies based on genres\n",
    "genres_similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Display a sample similarity score matrix (first 5 movies)\n",
    "print(\"Genres Similarity Matrix (first 5 movies):\")\n",
    "print(genres_similarity[:5, :5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGxY4D0CJ0zE"
   },
   "source": [
    "# 2.1.1: Incorporate Tags into Content-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVEw3gsqD5bq",
    "outputId": "85ec8c49-a578-4c0f-bba1-f6c6a8b8657d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\birne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Features for Movies (first 5 movies):\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                   combined_features  \n",
      "0  Adventure Animation Children Comedy Fantasy wa...  \n",
      "1  Adventure Children Fantasy time travel adapted...  \n",
      "2  Comedy Romance old people actually funny seque...  \n",
      "3  Comedy Drama Romance chick flick revenge chara...  \n",
      "4  Comedy diane keaton family sequel steve martin...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load the stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocess tags: Combine all tags for each movie\n",
    "tags['tag'] = tags['tag'].fillna('').str.lower()\n",
    "tags['tag'] = tags['tag'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))  # Remove non-alphabet characters\n",
    "tags_grouped = tags.groupby('movieId')['tag'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Merge the tags and movies datasets to combine genres and tags\n",
    "movies_tags = pd.merge(movies, tags_grouped, on='movieId', how='left')\n",
    "movies_tags['tag'] = movies_tags['tag'].fillna('')  # Replace NaN with an empty string\n",
    "\n",
    "# Combine genres and tags into a single feature\n",
    "movies_tags['combined_features'] = movies_tags['genres'] + ' ' + movies_tags['tag']\n",
    "\n",
    "# Apply text preprocessing: Remove stopwords from the combined features\n",
    "movies_tags['combined_features'] = movies_tags['combined_features'].apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in stop_words])\n",
    ")\n",
    "\n",
    "# Display a sample of the combined features\n",
    "print(\"Combined Features for Movies (first 5 movies):\")\n",
    "print(movies_tags[['movieId', 'title', 'combined_features']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lo-EkLIhKDt6"
   },
   "source": [
    "#Step 2.1.2: Vectorize Combined Features and Calculate Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDOHYhTEKGss",
    "outputId": "f9c1572d-7796-4c00-f051-8c43a4b22a38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Similarity Matrix (first 5 movies):\n",
      "[[1.         0.06603966 0.01117023 0.0048979  0.03516531]\n",
      " [0.06603966 1.         0.00105999 0.06323018 0.02403781]\n",
      " [0.01117023 0.00105999 1.         0.02789314 0.11785211]\n",
      " [0.0048979  0.06323018 0.02789314 1.         0.0245282 ]\n",
      " [0.03516531 0.02403781 0.11785211 0.0245282  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Use TF-IDF Vectorizer to convert the combined features into feature vectors\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(movies_tags['combined_features'])\n",
    "\n",
    "# Compute cosine similarity between movies based on combined features\n",
    "combined_similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Display a sample of the similarity matrix (first 5 movies)\n",
    "print(\"Combined Similarity Matrix (first 5 movies):\")\n",
    "print(combined_similarity[:5, :5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU0V8Q9zKyJ_"
   },
   "source": [
    "#Integrate Content-Based and Collaborative Filtering for Hybrid Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFrxwPHjK_ZI"
   },
   "source": [
    "#2.3: Calculate Hybrid Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HsysfSCeKRbq",
    "outputId": "e8f6d198-a370-464a-867d-66bc3675b994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid recommendation score for user 1 and movie 2: 2.5895\n"
     ]
    }
   ],
   "source": [
    "def hybrid_recommendation(user_id, movie_id, combined_similarity, svd_model, movies_df, weight_cf=0.7, weight_cb=0.3):\n",
    "    # Collaborative Filtering Score\n",
    "    cf_score = svd_model.predict(user_id, movie_id).est\n",
    "\n",
    "    # Content-Based Similarity Score\n",
    "    # Find the index of the movie_id in movies dataframe\n",
    "    try:\n",
    "        movie_idx = movies_df[movies_df['movieId'] == movie_id].index[0]\n",
    "    except IndexError:\n",
    "        # If movie_id is not found in the dataset, return a score of 0\n",
    "        return 0\n",
    "\n",
    "    # Calculate the average similarity score for the given movie to all movies rated by the user\n",
    "    user_rated_movies = ratings[ratings['userId'] == user_id]['movieId'].values\n",
    "    if len(user_rated_movies) > 0:\n",
    "        cb_score = np.mean([combined_similarity[movie_idx, movies_df[movies_df['movieId'] == m_id].index[0]] for m_id in user_rated_movies])\n",
    "    else:\n",
    "        cb_score = 0  # If no ratings by user, content-based score is 0\n",
    "\n",
    "    # Hybrid Score: Weighted combination of CF and CB\n",
    "    hybrid_score = (weight_cf * cf_score) + (weight_cb * cb_score)\n",
    "\n",
    "    return hybrid_score\n",
    "\n",
    "# Example usage: Predict a score for user 1 and movie 2\n",
    "user_id = 1\n",
    "movie_id = 2\n",
    "hybrid_score = hybrid_recommendation(user_id, movie_id, combined_similarity, best_svd, movies_tags)\n",
    "print(f\"Hybrid recommendation score for user {user_id} and movie {movie_id}: {hybrid_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lenkMy9QO-nj"
   },
   "source": [
    "#Step 2.4: Generate Recommendations for a User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uUaQX9wEM-Ez",
    "outputId": "be8acbf0-76fe-4c45-93ca-b759490b4f27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 movie recommendations for user 1:\n",
      "1. Octopus, The (Le poulpe) (1998) (Score: 3.3471)\n",
      "2. Marihuana (1936) (Score: 3.3176)\n",
      "3. Zero Motivation (Efes beyahasei enosh) (2014) (Score: 3.3119)\n",
      "4. Playing the Victim (Izobrazhaya zhertvu) (2006) (Score: 3.2837)\n",
      "5. Welfare (1975) (Score: 3.2223)\n",
      "6. Car Bonus (Autobonus) (2001) (Score: 3.2114)\n",
      "7. Johnny Express (2014) (Score: 3.2109)\n",
      "8. I Belong (Som du ser meg) (2012) (Score: 3.2019)\n",
      "9. Shepard & Dark (2012) (Score: 3.1959)\n",
      "10. Last Days in Vietnam (2014) (Score: 3.1821)\n"
     ]
    }
   ],
   "source": [
    "def generate_hybrid_recommendations(user_id, combined_similarity, svd_model, movies_df, ratings_df, num_recommendations=10, weight_cf=0.7, weight_cb=0.3):\n",
    "    # Get the list of all movie IDs\n",
    "    all_movie_ids = movies_df['movieId'].values\n",
    "\n",
    "    # Get the list of movies rated by the user\n",
    "    rated_movie_ids = ratings_df[ratings_df['userId'] == user_id]['movieId'].values\n",
    "\n",
    "    # Filter out movies that the user has already rated\n",
    "    movies_to_recommend = [movie_id for movie_id in all_movie_ids if movie_id not in rated_movie_ids]\n",
    "\n",
    "    # Calculate hybrid scores for all movies the user has not rated\n",
    "    hybrid_scores = []\n",
    "    for movie_id in movies_to_recommend:\n",
    "        score = hybrid_recommendation(user_id, movie_id, combined_similarity, svd_model, movies_df, weight_cf, weight_cb)\n",
    "        hybrid_scores.append((movie_id, score))\n",
    "\n",
    "    # Sort movies by hybrid score in descending order\n",
    "    hybrid_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top N movie recommendations\n",
    "    top_movies = hybrid_scores[:num_recommendations]\n",
    "\n",
    "    # Display the top recommendations with movie titles\n",
    "    recommendations = []\n",
    "    for movie_id, score in top_movies:\n",
    "        movie_title = movies_df[movies_df['movieId'] == movie_id]['title'].values[0]\n",
    "        recommendations.append((movie_title, score))\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# Example usage: Generate top 10 recommendations for user 1\n",
    "user_id = 1\n",
    "num_recommendations = 10\n",
    "top_recommendations = generate_hybrid_recommendations(user_id, combined_similarity, best_svd, movies_tags, ratings, num_recommendations)\n",
    "\n",
    "# Display the recommendations\n",
    "print(f\"Top {num_recommendations} movie recommendations for user {user_id}:\")\n",
    "for idx, (title, score) in enumerate(top_recommendations, start=1):\n",
    "    print(f\"{idx}. {title} (Score: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RW1jZFkVUQa_"
   },
   "source": [
    "#Evaluate Hybrid Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HIcR3W6HUf9X",
    "outputId": "016c0fa8-9903-4ece-9aac-aa08cd652fda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10 for user 1: 0.0000\n",
      "Recall@10 for user 1: 0.0000\n"
     ]
    }
   ],
   "source": [
    "def precision_recall_at_k(user_id, combined_similarity, svd_model, movies_df, ratings_df, k=10, weight_cf=0.7, weight_cb=0.3):\n",
    "    # Generate top K hybrid recommendations for the user\n",
    "    top_recommendations = generate_hybrid_recommendations(user_id, combined_similarity, svd_model, movies_df, ratings_df, num_recommendations=k, weight_cf=weight_cf, weight_cb=weight_cb)\n",
    "    recommended_movie_ids = [movies_df[movies_df['title'] == title]['movieId'].values[0] for title, score in top_recommendations]\n",
    "\n",
    "    # Get the list of movies rated by the user\n",
    "    user_ratings = ratings_df[ratings_df['userId'] == user_id]\n",
    "\n",
    "    # Define a relevant rating threshold (e.g., ratings >= 4 are considered relevant)\n",
    "    relevant_ratings = user_ratings[user_ratings['rating'] >= 4.0]\n",
    "    relevant_movie_ids = relevant_ratings['movieId'].values\n",
    "\n",
    "    # Calculate Precision and Recall\n",
    "    relevant_recommended = [movie_id for movie_id in recommended_movie_ids if movie_id in relevant_movie_ids]\n",
    "    precision = len(relevant_recommended) / len(recommended_movie_ids) if len(recommended_movie_ids) > 0 else 0\n",
    "    recall = len(relevant_recommended) / len(relevant_movie_ids) if len(relevant_movie_ids) > 0 else 0\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "# Example usage: Calculate precision and recall for user 1 for top 10 recommendations\n",
    "user_id = 1\n",
    "precision, recall = precision_recall_at_k(user_id, combined_similarity, best_svd, movies_tags, ratings, k=10)\n",
    "print(f\"Precision@10 for user {user_id}: {precision:.4f}\")\n",
    "print(f\"Recall@10 for user {user_id}: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KoC7Jnn9W3v"
   },
   "source": [
    "#Evaluating Precision and Recall for Multiple Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3xymnuMGzm8"
   },
   "outputs": [],
   "source": [
    "# def evaluate_precision_recall(users, combined_similarity, svd_model, movies_df, ratings_df, k=10, weight_cf=0.7, weight_cb=0.3):\n",
    "#     total_precision = 0\n",
    "#     total_recall = 0\n",
    "#     count_users = 0\n",
    "\n",
    "#     for user_id in users:\n",
    "#         # Calculate precision and recall for the given user\n",
    "#         precision, recall = precision_recall_at_k(user_id, combined_similarity, svd_model, movies_df, ratings_df, k, weight_cf, weight_cb)\n",
    "\n",
    "#         # Accumulate precision and recall\n",
    "#         total_precision += precision\n",
    "#         total_recall += recall\n",
    "#         count_users += 1\n",
    "\n",
    "#     # Calculate average precision and recall\n",
    "#     avg_precision = total_precision / count_users if count_users > 0 else 0\n",
    "#     avg_recall = total_recall / count_users if count_users > 0 else 0\n",
    "\n",
    "#     return avg_precision, avg_recall\n",
    "\n",
    "# # Example usage: Evaluate precision and recall for the first 100 users\n",
    "# user_ids = ratings['userId'].unique()[:100]  # Get the first 100 unique user IDs\n",
    "# avg_precision, avg_recall = evaluate_precision_recall(user_ids, combined_similarity, best_svd, movies_tags, ratings, k=10)\n",
    "\n",
    "# print(f\"Average Precision@10 for the first 100 users: {avg_precision:.4f}\")\n",
    "# print(f\"Average Recall@10 for the first 100 users: {avg_recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iLioQAg8wd7"
   },
   "source": [
    "#Finding the Best Weights for Hybrid Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wD8kbChR8vF9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_precision_recall' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Example usage: Find the best weights for the first 50 users\u001b[39;00m\n\u001b[0;32m     27\u001b[0m user_ids \u001b[38;5;241m=\u001b[39m ratings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()[:\u001b[38;5;241m50\u001b[39m]  \u001b[38;5;66;03m# Get the first 50 unique user IDs\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m best_weights, best_precision, best_recall \u001b[38;5;241m=\u001b[39m \u001b[43mfind_best_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_similarity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_svd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovies_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Display the best weights and their corresponding performance metrics\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest weights (CF, CB): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_weights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m, in \u001b[0;36mfind_best_weights\u001b[1;34m(users, combined_similarity, svd_model, movies_df, ratings_df, k)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Evaluate each combination of weights\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m weight_cf, weight_cb \u001b[38;5;129;01min\u001b[39;00m weight_combinations:\n\u001b[1;32m---> 12\u001b[0m     avg_precision, avg_recall \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_precision_recall\u001b[49m(\n\u001b[0;32m     13\u001b[0m         users, combined_similarity, svd_model, movies_df, ratings_df, k, weight_cf, weight_cb\n\u001b[0;32m     14\u001b[0m     )\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights CF: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_cf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, CB: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_cb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> Average Precision@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_precision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Average Recall@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_recall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Find the best combination based on precision and recall\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate_precision_recall' is not defined"
     ]
    }
   ],
   "source": [
    "def find_best_weights(users, combined_similarity, svd_model, movies_df, ratings_df, k=10):\n",
    "    weight_combinations = [\n",
    "        (0.1, 0.9), (0.2, 0.8), (0.3, 0.7), (0.4, 0.6), (0.5, 0.5),\n",
    "        (0.6, 0.4), (0.7, 0.3), (0.8, 0.2), (0.9, 0.1)\n",
    "    ]\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "    best_weights = None\n",
    "\n",
    "    # Evaluate each combination of weights\n",
    "    for weight_cf, weight_cb in weight_combinations:\n",
    "        avg_precision, avg_recall = evaluate_precision_recall(\n",
    "            users, combined_similarity, svd_model, movies_df, ratings_df, k, weight_cf, weight_cb\n",
    "        )\n",
    "\n",
    "        print(f\"Weights CF: {weight_cf}, CB: {weight_cb} -> Average Precision@{k}: {avg_precision:.4f}, Average Recall@{k}: {avg_recall:.4f}\")\n",
    "\n",
    "        # Find the best combination based on precision and recall\n",
    "        if avg_precision > best_precision or (avg_precision == best_precision and avg_recall > best_recall):\n",
    "            best_precision = avg_precision\n",
    "            best_recall = avg_recall\n",
    "            best_weights = (weight_cf, weight_cb)\n",
    "\n",
    "    return best_weights, best_precision, best_recall\n",
    "\n",
    "# Example usage: Find the best weights for the first 50 users\n",
    "user_ids = ratings['userId'].unique()[:50]  # Get the first 50 unique user IDs\n",
    "best_weights, best_precision, best_recall = find_best_weights(user_ids, combined_similarity, best_svd, movies_tags, ratings, k=10)\n",
    "\n",
    "# Display the best weights and their corresponding performance metrics\n",
    "print(f\"\\nBest weights (CF, CB): {best_weights}\")\n",
    "print(f\"Best Average Precision@10: {best_precision:.4f}\")\n",
    "print(f\"Best Average Recall@10: {best_recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "SEP24-BDS-INT-FILM-RECO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
