version: "3.10"
networks:
  monitoring:

services:
  data_split:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: data_split
    command: ["python", "src/data/data_split.py"]
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./metrics:/app/metrics
    depends_on: []

  grid_search:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: grid_search
    command: ["python", "src/models/model_grid_search.py"]
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./metrics:/app/metrics
    depends_on:
      data_split:
        condition: service_completed_successfully

  model_train:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: model_train
    environment:
      - BENTOML_HOME=/bentoml
    command: ["python", "src/models/model_train.py"]
    volumes:
      - ./bentoml:/bentoml
      - ./data:/app/data
      - ./models:/app/models
      - ./metrics:/app/metrics
    depends_on:
      grid_search:
        condition: service_completed_successfully 

  model_evaluate:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: model_evaluate
    env_file:
      - .env
    environment:
      - DAGSHUB_USER_TOKEN=${DAGSHUB_USER_TOKEN}
    command: ["python", "src/models/model_evaluate.py"]
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./metrics:/app/metrics
    depends_on:
      model_train:
        condition: service_completed_successfully 

  create_predictions:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: create_predictions
    command: ["python", "src/data/create_prediction_data.py"]
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./metrics:/app/metrics
    depends_on:
      model_evaluate:
        condition: service_completed_successfully 

  bentoml:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: bentoml
    ports:
      - "3000:3000" 
    environment:
      - BENTOML_HOME=/bentoml
    command: ["bentoml", "serve", "src/service.py"]
    volumes:
      - ./bentoml:/bentoml
      - ./data:/app/data
      - ./models:/app/models
      - ./metrics:/app/metrics
    depends_on:
      model_evaluate:
        condition: service_completed_successfully
    networks:
      - monitoring

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - ./alert_rules.yml:/etc/prometheus/alert_rules.yml
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--web.enable-lifecycle"
    ports:
      - "9090:9090"
    depends_on:
      - bentoml
    networks:
      - monitoring

  alertmanager:
    image: prom/alertmanager
    container_name: alertmanager
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
    command:
      - "--config.file=/etc/alertmanager/alertmanager.yml"
    ports:
      - "9093:9093"
    depends_on:
      - prometheus
    networks:
      - monitoring

  grafana:
    image: grafana/grafana
    container_name: grafana
    user: "472:472"
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ./grafana:/var/lib/grafana
    depends_on:
      - prometheus
    networks:
      - monitoring  
      
  evidently:
    build:
      context: .
      dockerfile: Dockerfile.evidently
    container_name: evidently
    ports:
      - "8000:8000"
    command: ["bash", "-c", "python src/evidently_service.py && evidently ui --workspace ./movie_recommender_workspace/ --host 0.0.0.0"]
    volumes:
      - ./data:/app/data
      - ./metrics:/app/metrics
    depends_on:
      create_predictions:
        condition: service_completed_successfully
        
  cadvisor:
    image: google/cadvisor:latest
    container_name: cadvisor
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
