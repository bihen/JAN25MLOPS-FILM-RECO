version: "3.10"

services:
  data_split:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: data_split
    command: ["python", "src/data/data_split.py"]
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./metrics:/app/metrics
    depends_on: []

  grid_search:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: grid_search
    command: ["python", "src/models/model_grid_search.py"]
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./metrics:/app/metrics
    depends_on:
      data_split:
        condition: service_completed_successfully

  model_train:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: model_train
    environment:
      - BENTOML_HOME=/bentoml
    command: ["python", "src/models/model_train.py"]
    volumes:
      - ./bentoml:/bentoml
      - ./data:/app/data
      - ./models:/app/models
      - ./metrics:/app/metrics
    depends_on:
      grid_search:
        condition: service_completed_successfully 

  model_evaluate:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: model_evaluate
    env_file:
      - .env
    environment:
      - DAGSHUB_USER_TOKEN=${DAGSHUB_USER_TOKEN}
    command: ["python", "src/models/model_evaluate.py"]
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./metrics:/app/metrics
    depends_on:
      model_train:
        condition: service_completed_successfully 

  create_predictions:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: create_predictions
    command: ["python", "src/data/create_prediction_data.py"]
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./metrics:/app/metrics
    depends_on:
      model_evaluate:
        condition: service_completed_successfully 

  bentoml:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: bentoml
    ports:
      - "3000:3000" 
    environment:
      - BENTOML_HOME=/bentoml
    command: ["bentoml", "serve", "src/service.py"]
    volumes:
      - ./bentoml:/bentoml
      - ./data:/app/data
      - ./models:/app/models
      - ./metrics:/app/metrics
    depends_on:
      model_evaluate:
        condition: service_completed_successfully

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
    ports:
      - "9090:9090"
    depends_on:
      - bentoml

  grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ./grafana:/var/lib/grafana
    depends_on:
      - prometheus

  #evidently:
  #  build:
  #    context: .
  #    dockerfile: Dockerfile.evidently  
  #  container_name: evidently
  #  ports:
  #    - "5000:5000"
  #  command: ["python", "src/monitoring/evidently_service.py"]
  #  volumes:
  #    - ./data:/app/data
  #    - ./metrics:/app/metrics
  #  depends_on:
  #    model_evaluate:
  #      condition: service_completed_successfully